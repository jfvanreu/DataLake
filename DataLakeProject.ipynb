{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Lake project using Spark and AWS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "A music streaming startup, Sparkify, has grown their user base and song database even more and want to move their data warehouse to a data lake. Their data resides in S3, in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app.\n",
    "\n",
    "In this project, we build an ETL pipeline that extracts Sparkify data from S3, processes them using Spark, and loads the data back into S3 as a set of dimensional tables. This will allow Sparkify analytics team to continue finding insights in what songs their users are listening to.\n",
    "\n",
    "In this project, we first review a small data and apply some transformations to it. Once those transformations are validated, we launch an AWS EMR instance and apply our ETL process on the larger dataset available on AWS S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Load Python packages and open a local Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, IntegerType, TimestampType\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Load & check Songs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfSongs = spark.read.json(\"./data/song_data/*/*/*/*.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Check the songs_data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfSongs.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Check the number of records and display first 5 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSongs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|         artist_id|artist_latitude|  artist_location|artist_longitude|         artist_name| duration|num_songs|           song_id|               title|year|\n",
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|ARDR4AC1187FB371A1|           null|                 |            null|Montserrat Caball...|511.16363|        1|SOBAYLL12A8C138AF9|Sono andati? Fing...|   0|\n",
      "|AREBBGV1187FB523D2|           null|      Houston, TX|            null|Mike Jones (Featu...|173.66159|        1|SOOLYAZ12A6701F4A6|Laws Patrolling (...|   0|\n",
      "|ARMAC4T1187FB3FA4C|       40.82624|Morris Plains, NJ|       -74.47995|The Dillinger Esc...|207.77751|        1|SOBBUGU12A8C13E95D|Setting Fire to S...|2004|\n",
      "|ARPBNLO1187FB3D52F|       40.71455|     New York, NY|       -74.00712|            Tiny Tim| 43.36281|        1|SOAOIBZ12AB01815BE|I Hold Your Hand ...|2000|\n",
      "|ARDNS031187B9924F0|       32.67828|          Georgia|       -83.22295|          Tim Wilson|186.48771|        1|SONYPOM12A8C13B2D7|I Think My Wife I...|2005|\n",
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfSongs.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Load & Check Logs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfLogs=spark.read.json(\"./data/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfLogs.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Check number of records for Log data and display first 5 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8056"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfLogs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+---------------+------+-------------+--------------------+------+\n",
      "|     artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page|     registration|sessionId|           song|status|           ts|           userAgent|userId|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+---------------+------+-------------+--------------------+------+\n",
      "|   Harmonia|Logged In|     Ryan|     M|            0|   Smith|655.77751| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|  Sehr kosmisch|   200|1542241826796|\"Mozilla/5.0 (X11...|    26|\n",
      "|The Prodigy|Logged In|     Ryan|     M|            1|   Smith|260.07465| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|The Big Gundown|   200|1542242481796|\"Mozilla/5.0 (X11...|    26|\n",
      "|      Train|Logged In|     Ryan|     M|            2|   Smith|205.45261| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|       Marry Me|   200|1542242741796|\"Mozilla/5.0 (X11...|    26|\n",
      "|       null|Logged In|    Wyatt|     M|            0|   Scott|     null| free|Eureka-Arcata-For...|   GET|    Home|1.540872073796E12|      563|           null|   200|1542247071796|Mozilla/5.0 (Wind...|     9|\n",
      "|       null|Logged In|   Austin|     M|            0| Rosales|     null| free|New York-Newark-J...|   GET|    Home|1.541059521796E12|      521|           null|   200|1542252577796|Mozilla/5.0 (Wind...|    12|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+---------------+------+-------------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfLogs.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create and Write Songs table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Extract relevant columns from songs data to create Songs table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOBAYLL12A8C138AF9|Sono andati? Fing...|ARDR4AC1187FB371A1|   0|511.16363|\n",
      "|SOOLYAZ12A6701F4A6|Laws Patrolling (...|AREBBGV1187FB523D2|   0|173.66159|\n",
      "|SOBBUGU12A8C13E95D|Setting Fire to S...|ARMAC4T1187FB3FA4C|2004|207.77751|\n",
      "|SOAOIBZ12AB01815BE|I Hold Your Hand ...|ARPBNLO1187FB3D52F|2000| 43.36281|\n",
      "|SONYPOM12A8C13B2D7|I Think My Wife I...|ARDNS031187B9924F0|2005|186.48771|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#extract relevant columns to create Songs table\n",
    "songs_table = dfSongs.filter(dfSongs.song_id != '')\\\n",
    "                     .select(['song_id', 'title', 'artist_id', 'year', 'duration']) \n",
    "songs_table.show(5)\n",
    "#write songs table partioned by year and artist to parquet\n",
    "songs_table.write.partitionBy(\"year\", \"artist_id\").mode('overwrite').parquet('./data/output/songs/songs_table.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create and Write Artists table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Extract relevant columns from songs data to create Artists table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+---------------+----------+--------+\n",
      "|         artist_id|           name|       location| longitude|latitude|\n",
      "+------------------+---------------+---------------+----------+--------+\n",
      "|ARPBNLO1187FB3D52F|       Tiny Tim|   New York, NY| -74.00712|40.71455|\n",
      "|ARXR32B1187FB57099|            Gob|               |      null|    null|\n",
      "|AROGWRA122988FEE45|Christos Dantis|               |      null|    null|\n",
      "|ARBGXIG122988F409D|     Steel Rain|California - SF|-122.42005|37.77916|\n",
      "|AREVWGE1187B9B890A|     Bitter End|      Noci (BA)|  -41.9952| -13.442|\n",
      "+------------------+---------------+---------------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#extract relevant columns to create Artists table\n",
    "artists_table = dfSongs.filter(dfSongs.artist_id !='') \\\n",
    "                        .select(col(\"artist_id\"),col(\"artist_name\").alias(\"name\"), col(\"artist_location\").alias(\"location\"),\n",
    "                                 col(\"artist_longitude\").alias(\"longitude\"), col(\"artist_latitude\").alias(\"latitude\"))\\\n",
    "                        .dropDuplicates()\n",
    "artists_table.show(5)\n",
    "\n",
    "#write artists table while renaming column headers\n",
    "artists_table.write.mode('overwrite').parquet('./data/output/artists/artists_table.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Filter 'NextPage' records in Log data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|     artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page|     registration|sessionId|                song|status|           ts|           userAgent|userId|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|   Harmonia|Logged In|     Ryan|     M|            0|   Smith|655.77751| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|       Sehr kosmisch|   200|1542241826796|\"Mozilla/5.0 (X11...|    26|\n",
      "|The Prodigy|Logged In|     Ryan|     M|            1|   Smith|260.07465| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|     The Big Gundown|   200|1542242481796|\"Mozilla/5.0 (X11...|    26|\n",
      "|      Train|Logged In|     Ryan|     M|            2|   Smith|205.45261| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|            Marry Me|   200|1542242741796|\"Mozilla/5.0 (X11...|    26|\n",
      "|Sony Wonder|Logged In|   Samuel|     M|            0|Gonzalez|218.06975| free|Houston-The Woodl...|   PUT|NextSong|1.540492941796E12|      597|           Blackbird|   200|1542253449796|\"Mozilla/5.0 (Mac...|    61|\n",
      "|  Van Halen|Logged In|    Tegan|     F|            2|  Levine|289.38404| paid|Portland-South Po...|   PUT|NextSong|1.540794356796E12|      602|Best Of Both Worl...|   200|1542260935796|\"Mozilla/5.0 (Mac...|    80|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfNextSongLogs=dfLogs.filter(dfLogs.page == 'NextSong')\n",
    "dfNextSongLogs.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create and Write Users table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     26|      Ryan|    Smith|     M| free|\n",
      "|      7|    Adelyn|   Jordan|     F| free|\n",
      "|     71|    Ayleen|     Wise|     F| free|\n",
      "|     81|    Sienna|    Colon|     F| free|\n",
      "|     87|    Dustin|      Lee|     M| free|\n",
      "|     23|    Morris|  Gilmore|     M| free|\n",
      "|     75|    Joseph|Gutierrez|     M| free|\n",
      "|     16|     Rylan|   George|     M| paid|\n",
      "|      2|   Jizelle| Benjamin|     F| free|\n",
      "|      3|     Isaac|   Valdez|     M| free|\n",
      "|     54|     Kaleb|     Cook|     M| free|\n",
      "|     79|     James|   Martin|     M| free|\n",
      "|     80|     Tegan|   Levine|     F| paid|\n",
      "|     77| Magdalene|   Herman|     F| free|\n",
      "|     47|    Kimber|   Norris|     F| free|\n",
      "|     30|     Avery|  Watkins|     F| paid|\n",
      "|     22|      Sean|   Wilson|     F| free|\n",
      "|      4|    Alivia|  Terrell|     F| free|\n",
      "|     55|    Martin|  Johnson|     M| free|\n",
      "|     20|     Aiden|  Ramirez|     M| paid|\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#extract relevant columns to create Users table\n",
    "users_table = dfNextSongLogs.filter(dfNextSongLogs.userId !='') \\\n",
    "                        .select(col(\"userId\").alias(\"user_id\"),col(\"firstName\").alias(\"first_name\"), col(\"lastName\").alias(\"last_name\"),\n",
    "                                 col(\"gender\"), col(\"level\")) \\\n",
    "                        .dropDuplicates()\n",
    "\n",
    "users_table.show(20)\n",
    "\n",
    "#write users table\n",
    "users_table.write.mode('overwrite').parquet('./data/output/users/users_table.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create and Write Time table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|          start_time|hour|day|week|month|year|weekday|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|2018-11-15 00:30:...|   0| 15|  46|   11|2018|      5|\n",
      "|2018-11-15 00:41:...|   0| 15|  46|   11|2018|      5|\n",
      "|2018-11-15 00:45:...|   0| 15|  46|   11|2018|      5|\n",
      "|2018-11-15 03:44:...|   3| 15|  46|   11|2018|      5|\n",
      "|2018-11-15 05:48:...|   5| 15|  46|   11|2018|      5|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, month, dayofyear, hour, dayofweek, weekofyear, date_format\n",
    "from datetime import datetime\n",
    "\n",
    "#start_time, hour, day, week, month, year, weekday\n",
    "\n",
    "# create timestamp column from original timestamp column\n",
    "get_timestamp = udf(lambda ms: datetime.fromtimestamp(ms/1000.0), TimestampType())\n",
    "dfNextSongLogs = dfNextSongLogs.withColumn('start_time', get_timestamp('ts'))\n",
    "    \n",
    "# extract columns to create time table\n",
    "time_table = dfNextSongLogs.select('start_time')\\\n",
    "                            .withColumn('hour',hour('start_time')).withColumn('day',dayofmonth('start_time'))\\\n",
    "                            .withColumn('week',weekofyear('start_time')).withColumn('month', month('start_time'))\\\n",
    "                            .withColumn('year', year('start_time')).withColumn('weekday',dayofweek('start_time'))\n",
    "time_table.show(5)\n",
    "\n",
    "# write time table to parquet files partitioned by year and month\n",
    "time_table.write.partitionBy(\"year\", \"month\").mode('overwrite').parquet('./data/output/time/time_table.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create and Write SongPlays table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+---+\n",
      "|          start_time|user_id|level|           song_id|         artist_id|session_id|            location|          user_agent|year|month|idx|\n",
      "+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+---+\n",
      "|2018-11-21 21:56:...|     15| paid|SOZCTXZ12AB0182364|AR5KOSW1187FB35FF4|       818|Chicago-Napervill...|\"Mozilla/5.0 (X11...|2018|   11|882|\n",
      "+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract columns from joined song and log datasets to create songplays table\n",
    "\n",
    "songplays_table = dfNextSongLogs.join(dfSongs, (dfNextSongLogs.song == dfSongs.title) & (dfNextSongLogs.length == dfSongs.duration), 'left_outer')\\\n",
    "        .select(\n",
    "            dfNextSongLogs.start_time,\n",
    "            col(\"userId\").alias('user_id'),\n",
    "            dfNextSongLogs.level,\n",
    "            dfSongs.song_id,\n",
    "            dfSongs.artist_id,\n",
    "            col(\"sessionId\").alias(\"session_id\"),\n",
    "            dfNextSongLogs.location,\n",
    "            col(\"useragent\").alias(\"user_agent\"),\n",
    "            year('start_time').alias('year'),\n",
    "            month('start_time').alias('month'))\\\n",
    "        .withColumn(\"idx\", monotonically_increasing_id())\n",
    "\n",
    "songplays_table=songplays_table.filter(\"song_id is not null and artist_id is not null\")\n",
    "songplays_table.show(5)\n",
    "\n",
    "# write songplays table to parquet files partitioned by year and month\n",
    "songplays_table.write.partitionBy(\"year\", \"month\").mode('overwrite').parquet('./data/output/songplays/songplays_table.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
